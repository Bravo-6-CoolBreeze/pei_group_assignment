{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f44b435-1afc-4710-9242-9fe3c8c713a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, regexp_replace, trim, when, length, to_date, round, year, sum\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DecimalType, IntegerType, DateType\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "import pandas as pd\n",
    "import re\n",
    "import logging\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2aa8a03f-a0a1-47fc-bf86-779d1b9d7c7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def clean_column_name(column_name):\n",
    "    \"\"\"Clean column names by removing invalid characters and replacing space with underscore.\"\"\"\n",
    "    cleaned_name = re.sub(r\"[,\\;\\{\\}\\(\\)=]\", \"\", column_name).lower()\n",
    "    return re.sub(r\"[\\s]\", \"_\", cleaned_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ac58635-da30-4871-9996-d27be2d17d85",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def write_df_to_table(df, trg_tbl_nm):\n",
    "    \"\"\"Write dataframe to Delta Table\"\"\"\n",
    "    try:\n",
    "        # Save to Delta table\n",
    "        df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(trg_tbl_nm)\n",
    "        logger.info(f\"Table {trg_tbl_nm} created successfully\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading table {trg_tbl_nm}: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c075e891-53e0-401f-9930-28922b4f4c26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def read_raw_customers(file_path):\n",
    "    \"\"\"Read raw customers data from file\"\"\"\n",
    "    try:\n",
    "        pd_df = pd.read_excel(file_path, engine=\"openpyxl\", dtype=\"str\", na_filter=False)\n",
    "        df = spark.createDataFrame(pd_df)\n",
    "\n",
    "        # Clean column names\n",
    "        for column in df.columns:\n",
    "            df = df.withColumnRenamed(column, clean_column_name(column))\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error reading customer file: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "069aad94-7945-4cd6-aeda-e47fe1174282",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def read_raw_orders(file_path):\n",
    "    \"\"\"Read raw orders data from file\"\"\"\n",
    "    try:\n",
    "        df = spark.read.option(\"multiLine\", \"true\").option(\"primitivesAsString\", \"true\").json(file_path)\n",
    "\n",
    "        # Clean column names\n",
    "        for column in df.columns:\n",
    "            df = df.withColumnRenamed(column, clean_column_name(column))\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error reading orders file: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4444b4e4-11a5-4b94-825a-c791e3eeda81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def read_raw_products(file_path):\n",
    "    \"\"\"Read raw products data from file\"\"\"\n",
    "    try:\n",
    "        product_schema = StructType([\n",
    "                            StructField(\"product_id\", StringType(), True),\n",
    "                            StructField(\"category\", StringType(), True),\n",
    "                            StructField(\"sub_category\", StringType(), True),\n",
    "                            StructField(\"product_name\", StringType(), True),\n",
    "                            StructField(\"state\", StringType(), True),\n",
    "                            StructField(\"price_per_product\", StringType(), True)\n",
    "                        ]) \n",
    "        df = spark.read.option(\"quote\", '\"').option(\"escape\", '\"').option(\"mode\", \"FAILFAST\").schema(product_schema).csv(file_path, header=True)\n",
    "\n",
    "        # Clean column names\n",
    "        for column in df.columns:\n",
    "            df = df.withColumnRenamed(column, clean_column_name(column))\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error reading products file: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17f9b872-2b60-4440-a94c-6a858fc56062",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def clean_customers(df):\n",
    "    \"\"\"Clean customers raw data\"\"\"\n",
    "    try:\n",
    "        # Trim all columns\n",
    "        for column in df.columns:\n",
    "            df = df.withColumn(column, trim(col(column)))\n",
    "        \n",
    "        df = (\n",
    "                df.withColumn(\"customer_name\", \n",
    "                                    when(regexp_replace(col(\"customer_name\"), r\"[^A-Za-z]\", \"\") != \"\", \n",
    "                                            regexp_replace(col(\"customer_name\"), r\"[^A-Za-z]\", \"\"))\n",
    "                                        .otherwise(None))\n",
    "                    .withColumn(\"phone\", \n",
    "                                    when(length(regexp_replace(col(\"phone\"), r\"\\D\", \"\")) >= 10,\n",
    "                                            regexp_replace(col(\"phone\"), r\"\\D\", \"\"))\n",
    "                                        .otherwise(None))\n",
    "        )\n",
    "\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error cleaning customer data: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13606da3-1d77-4e3a-b243-5a7799747a3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def clean_orders(df):\n",
    "    \"\"\"Clean orders raw data\"\"\"\n",
    "    try:\n",
    "        # Trim all columns\n",
    "        for column in df.columns:\n",
    "            df = df.withColumn(column, trim(col(column)))\n",
    "        \n",
    "        df = (\n",
    "                df.withColumn(\"order_date\", to_date(col(\"order_date\"), \"d/M/yyyy\"))\n",
    "                    .withColumn(\"ship_date\", to_date(col(\"ship_date\"), \"d/M/yyyy\"))\n",
    "                    .withColumn(\"discount\", col(\"discount\").cast(DecimalType(10, 2)))\n",
    "                    .withColumn(\"price\", col(\"price\").cast(DecimalType(10, 2)))\n",
    "                    .withColumn(\"profit\", col(\"profit\").cast(DecimalType(10, 2)))\n",
    "                    .withColumn(\"quantity\", col(\"quantity\").cast(IntegerType()))\n",
    "            )\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error cleaning orders data : {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02176c62-48f2-40b2-9ca5-486bf579603a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def clean_products(df):\n",
    "    \"\"\"Clean products raw data\"\"\"\n",
    "    try:\n",
    "        # Trim all columns\n",
    "        for column in df.columns:\n",
    "            df = df.withColumn(column, trim(col(column)))\n",
    "        \n",
    "        df = df.withColumn(\"price_per_product\", col(\"price_per_product\").cast(DecimalType(10, 2)))\n",
    "\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error cleaning products data: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2c6806f-91e8-435d-b87b-7bd6e4983c3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_enriched_orders_df(cleaned_customers_df, cleaned_orders_df, cleaned_products_df):\n",
    "    \"\"\"Create enriched orders master data\"\"\"\n",
    "    try:\n",
    "        enriched_orders_df = (\n",
    "                cleaned_orders_df.alias(\"o\").join(cleaned_customers_df.alias(\"c\"), \n",
    "                                                    on = [\"customer_id\"], how = \"inner\")\n",
    "                                .join(cleaned_products_df.alias(\"p\"), \n",
    "                                        on = [(col(\"o.product_id\") == col(\"p.product_id\")), \n",
    "                                              (col(\"c.state\") == col(\"p.state\"))], \n",
    "                                        how = \"inner\")\n",
    "                                .withColumn(\"profit\", round(col(\"o.profit\"), 2))\n",
    "                                .select(\n",
    "                                    col(\"c.customer_id\"),\n",
    "                                    col(\"c.customer_name\"),\n",
    "                                    col(\"c.country\"),\n",
    "                                    col(\"p.product_name\"),\n",
    "                                    col(\"p.sub_category\"),\n",
    "                                    col(\"p.category\"),\n",
    "                                    col(\"o.price\"),\n",
    "                                    col(\"o.quantity\"),\n",
    "                                    col(\"o.discount\"),\n",
    "                                    col(\"profit\"),\n",
    "                                    col(\"o.order_date\"),\n",
    "                                    col(\"o.ship_date\"),\n",
    "                                    col(\"o.ship_mode\")\n",
    "                                )\n",
    "        )\n",
    "        return enriched_orders_df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error creating enriched orders master dataset: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc8d798c-5e8e-4adb-a70a-7f3108b0891d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_aggregated_profit_df(enriched_df):\n",
    "    \"\"\"Create aggregated profit dataset\"\"\"\n",
    "    try:\n",
    "        aggregated_df = (\n",
    "        enriched_df.withColumn(\"year\", year(col(\"order_date\")))\n",
    "                        .groupBy(\"year\", \"category\", \"sub_category\", \"customer_id\", \"customer_name\")\n",
    "                            .agg(round(sum(col(\"profit\")), 2).alias(\"total_profit\"))\n",
    "                            .orderBy(\"year\", \"category\", \"sub_category\", \"customer_id\")\n",
    "                )\n",
    "\n",
    "        return aggregated_df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error creating aggregated profit dataset: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad1d3e45-8b9c-4600-a161-815a5230f7a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "customer_data_file_path = \"/Volumes/sales/bronze/raw_data_files/Customer.xlsx\"\n",
    "orders_data_file_path = \"/Volumes/sales/bronze/raw_data_files/Orders.json\"\n",
    "products_data_file_path = \"/Volumes/sales/bronze/raw_data_files/Products.csv\"\n",
    "\n",
    "catalog_name = \"sales\"\n",
    "\n",
    "raw_database_name = \"bronze\"\n",
    "\n",
    "enriched_database_name = \"silver\"\n",
    "\n",
    "aggregated_database_name = \"gold\"\n",
    "\n",
    "raw_customers_table_name = f\"{catalog_name}.{raw_database_name}.customers_raw\"\n",
    "raw_orders_table_name = f\"{catalog_name}.{raw_database_name}.orders_raw\"\n",
    "raw_products_table_name = f\"{catalog_name}.{raw_database_name}.products_raw\"\n",
    "\n",
    "cleaned_customers_table_name = f\"{catalog_name}.{enriched_database_name}.customers_cleaned\"\n",
    "cleaned_orders_table_name = f\"{catalog_name}.{enriched_database_name}.orders_cleaned\"\n",
    "cleaned_products_table_name = f\"{catalog_name}.{enriched_database_name}.products_cleaned\"\n",
    "\n",
    "enriched_orders_table_name = f\"{catalog_name}.{enriched_database_name}.sales_enriched_master\"\n",
    "\n",
    "aggregated_profit_table_name = f\"{catalog_name}.{aggregated_database_name}.aggregated_profit\""
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5394608707401254,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "sales_data_processing_helper",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}